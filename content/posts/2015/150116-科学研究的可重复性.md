---
title: 科学研究的可重复性
date: 2015-01-16T02:28:49+08:00
tags: [ 科研, 可重复性 ]
host-at: GitHub
---
昨天收到一封来自[PLOS]的推送邮件，提到其对斯坦福大学的[John Ioannidis]教授的[采访]（及其[视频]），采访内容主要关于其发表在《[PLOS Medicine]》上的关于科研结果正确性的两篇论文。其中第一篇《[Why Most Published Research Findings Are False][paper1]》发表于2005年8月，到2014年4月累计浏览量超过了百万（是PLOS上第一篇达到这么高浏览量的论文），可见该论文备受关注的程度及其影响。而第二篇《[How to Make More Published Research True][paper2]》发表于2014年10月，看起来像是应邀对前一篇论文的呼应发稿，时隔将近10年，尝试对前一篇论文所抛出的问题给出一些新的建设性的回答。由于比较感兴趣，我便将采访视频及两篇论文都仔细看了一遍，并自己简单总结一下，于是有了本文。

第一篇论文的标题（中文意为“为什么大多数科研发现都是假的”）起初看来挺吓人，这大概也是这篇论文的浏览量如此之大的一个重要原因。而当精读其正文后，却能认识到这种现象确实真实存在，一点儿也不夸张。

这篇论文从统计学上最基础的[第一类错误和第二类错误][errors]的定义出发，研究了不同参数（包括样本、偏差、独立实验的数目等）对于最后的PPV（[Positive Predictive Value][ppv]，也就是“对于一个科学发现，它是真的”的概率）的影响。其推导相当简单，看着简直就像一个生物统计学的课后作业。然而对于所得出的结果的总结描述，却是很出人意料的，这里引用其文中的几点推论：

1. 研究的规模越小，结果就越可能不是真的（“The smaller the studies conducted in a scientific field, the less likely the research findings are to be true”）；
2. 研究的有效样本数目越小，结果就越可能不是真的（“The smaller the effect sizes in a scientific field, the less likely the research findings are to be true”）；
3. 研究的总体越大、该发现所发生样本占总体的比例越小，结果就越可能不是真的（“The greater the number and the lesser the selection of tested relationships in a scientific field, the less likely the research findings are to be true”）；
4. 研究实验设计越灵活精细，结果就越可能不是真的（“The greater the flexibility in designs, definitions, outcomes, and analytical modes in a scientific field, the less likely the research findings are to be true”）；
5. 研究若存在财务或其它的偏见因素越多，结果就越可能不是真的（“The greater the financial and other interests and prejudices in a scientific field, the less likely the research findings are to be true”）；
6. 研究领域越热（有越多的实验室参与进来），结果就越可能不是真的（“The hotter a scientific field (with more scientific teams involved), the less likely the research findings are to be true”）。

这里的“结果就越可能不是真的”，指的就是那个PPV的概率值很小，即论文的标题中所述的“大多数科研结果都是假的”。而且由于存在这诸多导致“结果就越可能不是真的”的因素，它们叠加起来，就导致了绝大多数科研发现都只是那“1-PPV”的部分。

这其实是在生物医学（以及包括其它像心理学、社会学等）研究领域中长久以来普遍存在的问题。究其原因还是在于对统计方法的理解不够和P值被过度滥用的结果。虽然统计学对于科研的实验设计和结果分析都至关重要，但却并不是每个做科研的人都能很好地掌握这些必要的统计知识和方法的。P值作为一个简单易用的指标，被各种软件给出之后，就被直接用于最终发表的论文。而往往大家在看到统计显著性之后，就忘了背后更重要的模型，直接把结果泛化成为普遍真理。

虽然现状如此不乐观，但并不能由此否定科学的意义。John在采访中就提到，相比其它如宗教等，科学至少提供了解决问题和逐步纠正错误的方法。

很庆幸这几年来我们实验室也非常重视这类科研结果的正确分析和表述的问题，导师甚至专门请了国外的老师回来给同学们上统计课，以强调实验设计和科研结果可重复的重要性。在课上也提到了著名的R包[knitr]，以及由此逐渐形成的一套可实践的方法，以便让计算生物学和生物信息学（尤其在高通量测序数据分析时代的今天）的过程变得更可能被正确重复出来。

想到两年多以前我开始写[SeqPipe]这个小工具，目的也是为了在Linux高性能计算的服务器上，能够比较方便地将分析流程记录下来，实现科研分析步骤的可追溯，以保证结果的可重复性。

要实现科研结果的可重复，确实需要多方面的努力，想来任重而道远，还是有很多事情可以继续做的。

[PLOS]: http://www.plos.org/
[PLOS Medicine]: http://journals.plos.org/plosmedicine/
[John Ioannidis]: https://med.stanford.edu/profiles/john-ioannidis
[采访]: http://blogs.plos.org/speakingofmedicine/2014/06/23/one-one-million-article-views-qa-author-john-ioannidis/
[视频]: https://www.youtube.com/watch?v=KOZAV9AvIQE
[paper1]: http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124
[paper2]: http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001747
[errors]: http://en.wikipedia.org/wiki/Type_I_and_type_II_errors
[ppv]: http://en.wikipedia.org/wiki/Positive_and_negative_predictive_values
[knitr]: http://yihui.name/knitr/
[SeqPipe]: /seqpipe/
